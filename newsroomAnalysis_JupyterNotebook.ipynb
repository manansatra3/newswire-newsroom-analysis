{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import date as dateClass, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Declaring dictionaries for storage of data\n",
    "\n",
    "locationDictionary={}\n",
    "categoryDictionary={}\n",
    "tagsDictionary={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a VALID date in MM-DD-YYYY format. Example: 01-31-2018 or LEAVE BLANK for DEFAULTof past 7 days\n",
      "08-26-2018\n",
      "Starting to scrape newsroom data for analysis....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Date Calculations\n",
    "\n",
    "dateCorrect=False\n",
    "while dateCorrect!=True:\n",
    "    dateInput=raw_input(\"Enter a VALID date in MM-DD-YYYY format. Example: 01-31-2018 or LEAVE BLANK for DEFAULTof past 7 days\\n\")\n",
    "    if(dateInput==''):\n",
    "        print \"No Date Provided. Using a default of past 7 days data.\"\n",
    "        dateInput1=dateClass.today() - timedelta(days=7)\n",
    "        year= dateInput1.year\n",
    "        month= dateInput1.month\n",
    "        date= dateInput1.day\n",
    "        print \"Starting to scrape newsroom data for analysis....\"\n",
    "        break\n",
    "    else:\n",
    "        month=int(dateInput.split(\"-\")[0])\n",
    "        date=int(dateInput.split(\"-\")[1])\n",
    "        year=int(dateInput.split(\"-\")[2])\n",
    "        try:\n",
    "            dateInput1=dateClass(year,month,date)\n",
    "            if (dateInput1 <= dateClass.today()):\n",
    "                dateCorrect=True\n",
    "                print \"Starting to scrape newsroom data for analysis....\\n\"\n",
    "            else:\n",
    "                print \"Date entered is after today's date. Enter today's date or past date\\n\"\n",
    "        except ValueError:\n",
    "            print \"INVALID DATE entered. Try again..\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making a request to the webpage and getting beautiful soup object\n",
    "\n",
    "page = requests.get(\"https://www.newswire.com/newsroom\")    \n",
    "if page.status_code==200:   \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "else:\n",
    "    print \"HTTP Request Rejected by: https://www.newswire.com/newsroom\\tTry again later\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to map months to month number\n",
    "def monthToIntMonth(articleMonth):\n",
    "    switcher = {\n",
    "            \"Jan\":1,\n",
    "            \"Feb\":2,\n",
    "            \"Mar\":3,\n",
    "            \"Apr\":4,\n",
    "            \"May\":5,\n",
    "            \"Jun\":6,\n",
    "            \"Jul\":7,\n",
    "            \"Aug\":8,\n",
    "            \"Sep\":9,\n",
    "            \"Oct\":10,\n",
    "            \"Nov\":11,\n",
    "            \"Dec\":12\n",
    "        }\n",
    "    return switcher.get(articleMonth, \"Invalid month\")\n",
    "\n",
    "#function to generate soup object for inidivual article page\n",
    "def getSoupArticle(url):\n",
    "    pageArticle = requests.get(url)    \n",
    "    if pageArticle.status_code==200:   \n",
    "        soupArticle = BeautifulSoup(pageArticle.content, 'html.parser')\n",
    "    else:\n",
    "        print \"HTTP Request Rejected by: \"+url+\"\\tTry again later\"\n",
    "    return soupArticle\n",
    "\n",
    "#function to extract location, category and tag data from article URLs\n",
    "def getArticleData(soupArticle):\n",
    "    #getting location data\n",
    "    locList=soupArticle.select(\"p strong.date-line.color-pr\")[0].get_text().strip().lower().split(\",\")[:-2]\n",
    "    location=[]\n",
    "    for loc in locList:\n",
    "        loc=loc.lstrip().rstrip()\n",
    "        location.append(loc)\n",
    "    for loc in location:     \n",
    "        if loc in locationDictionary.keys():\n",
    "            locationDictionary[loc]+=1\n",
    "        else:\n",
    "            locationDictionary[loc]=1\n",
    "    \n",
    "    #getting category data\n",
    "    try:\n",
    "        catSoup=soupArticle.select(\"p[class=mb-0]\")[0]\n",
    "        catListLen=len(catSoup.select(\"a\"))\n",
    "        for i in range(0,catListLen):\n",
    "            catList=str(catSoup.select(\"a\")[i].get_text().encode('utf-8').lower()).split(\",\")\n",
    "            for cat in catList:\n",
    "                cat=cat.lstrip()\n",
    "                if cat in categoryDictionary.keys():\n",
    "                    categoryDictionary[cat]+=1\n",
    "                else:\n",
    "                    categoryDictionary[cat]=1\n",
    "    except IndexError:\n",
    "        pass\n",
    "    #getting tag data\n",
    "    try:\n",
    "        tagSoup=soupArticle.select(\"p[class=mb-0]\")[1]\n",
    "        tagListLen=len(tagSoup.select(\"a\"))\n",
    "        for i in range(0,tagListLen):\n",
    "            tagList=str(tagSoup.select(\"a\")[i].get_text().encode('utf-8').lower()).split(\",\")\n",
    "            for tag in tagList:\n",
    "                if tag in tagsDictionary.keys():\n",
    "                    tagsDictionary[tag]+=1\n",
    "                else:\n",
    "                    tagsDictionary[tag]=1\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/27/2018 -- https://www.newswire.com/news/stunning-new-necklaces-that-awaken-the-warrior-princess-within-20617460\n",
      "8/26/2018 -- https://www.newswire.com/news/millennial-mom-jenna-barnett-spotlights-female-founded-brands-in-20614837\n",
      "8/26/2018 -- https://www.newswire.com/news/i-accident-lawyer-shares-tips-for-passengers-involved-in-an-uber-20613409\n"
     ]
    }
   ],
   "source": [
    "#traversing articles using beautiful soup until the appropriate date\n",
    "nextPageTraverse=True\n",
    "while(nextPageTraverse):\n",
    "    divs=soup.select(\"div.news-item-body\")\n",
    "    for div in divs:\n",
    "        p=div.select(\"time.ln-date\")[0]\n",
    "        articleDate=p.get_text().split(\" \")\n",
    "        articleDay=int(str(articleDate[1]).replace(',',''))\n",
    "        articleMonth=int(monthToIntMonth(str(articleDate[0]).strip()))\n",
    "        articleYear=int(articleDate[2])\n",
    "        if(articleYear>=year):\n",
    "            if(articleMonth>=month):\n",
    "                if(articleDay>=date):\n",
    "                    url=\"https://www.newswire.com/\"+div.select(\"a.content-link\")[0]['href']\n",
    "                    print str(articleMonth) + \"/\" + str(articleDay) + \"/\" + str(articleYear)+\" -- \"+url\n",
    "                    soupArticle=getSoupArticle(url)\n",
    "                    getArticleData(soupArticle)\n",
    "                else:\n",
    "                    nextPageTraverse=False\n",
    "                    break\n",
    "            else:\n",
    "                nextPageTraverse=False\n",
    "                break\n",
    "        else:\n",
    "            nextPageTraverse=False\n",
    "            break\n",
    "    nextPage=soup.select(\"div.chunkination.chunkination-centered ul\")[2]\n",
    "    try:\n",
    "        nextPage=str(nextPage.find(\"a\")['href'])\n",
    "        url=\"https://www.newswire.com/\"+nextPage\n",
    "        page = requests.get(url)    \n",
    "        if page.status_code==200:   \n",
    "            soup = BeautifulSoup(page.content, 'html.parser') \n",
    "    except:\n",
    "        print 'No Next Page. End of results'\n",
    "        nextPageTraverse=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating LocationAnalysis bar graph\n",
    "print \"\\n\\nLocation Analysis Graph (LocationAnalysis.png) is save locally in your CWD: \"+os.getcwd()\n",
    "fig, ax = plt.subplots(figsize=(50,25))\n",
    "plt.bar(range(len(locationDictionary)), locationDictionary.values(), align='center')\n",
    "plt.xticks(range(len(locationDictionary)), locationDictionary.keys(),rotation='vertical', fontsize='12')\n",
    "plt.xlabel('Locations')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.savefig('LocationAnalysis.png')\n",
    "\n",
    "printTable=\"\"\n",
    "while printTable==\"\":\n",
    "    printTable=raw_input(\"\\nDo you want to print the Location Analysis Table (Y/N)?: \")\n",
    "    if(printTable=='Y' or printTable=='y'):\n",
    "        #generating location analysis frequency table\n",
    "        locDict1={}\n",
    "        maxLen=0\n",
    "        for k,v in locationDictionary.iteritems():\n",
    "            k=k.encode('ascii','ignore')\n",
    "            locDict1[k]=v\n",
    "            if(maxLen<len(k)):\n",
    "                maxLen=len(k)\n",
    "\n",
    "        print \"Location\"+' '*(maxLen+2)+\"| Number of Article\"\n",
    "        print '-'*(maxLen+32)\n",
    "        for k,v in locDict1.iteritems():\n",
    "            print k+' '*(maxLen-len(k)+10)+\"|\"+' '*10+str(v)\n",
    "        break\n",
    "    elif(printTable=='N' or printTable=='n'):\n",
    "        break\n",
    "    else:\n",
    "        print \"\\nInvalid Input try again\"\n",
    "        printTable=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Category Analysis Graph (CategoryAnalysis.png) is save locally in your CWD: D:\\HIGHER STUDIES\\Stevens\\Job Search\\Fall Internship\\Indeed\\newswire.com\\Coding Test\n",
      "\\Do you want to print the Category Analysis Table (Y/N)?: n\n"
     ]
    }
   ],
   "source": [
    "#Generate CategoryAnalysis bar graph\n",
    "print \"\\n\\nCategory Analysis Graph (CategoryAnalysis.png) is save locally in your CWD: \"+os.getcwd()\n",
    "fig, ax = plt.subplots(figsize=(50,25))\n",
    "plt.bar(range(len(categoryDictionary)), categoryDictionary.values(), align='center')\n",
    "plt.xticks(range(len(categoryDictionary)), categoryDictionary.keys(),rotation='vertical', fontsize='12')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.savefig('CategoryAnalysis.png')\n",
    "\n",
    "printTable=\"\"\n",
    "while printTable==\"\":\n",
    "    printTable=raw_input(\"\\Do you want to print the Category Analysis Table (Y/N)?: \")\n",
    "    if(printTable=='Y' or printTable=='y'):\n",
    "        maxLen=0\n",
    "        for k,v in categoryDictionary.iteritems():\n",
    "            if(maxLen<len(k)):\n",
    "                maxLen=len(k)\n",
    "\n",
    "        print \"Category\"+' '*(maxLen+2)+\"| Number of Article\"\n",
    "        print '-'*(maxLen+32)\n",
    "        for k,v in categoryDictionary.iteritems():\n",
    "            print k+' '*(maxLen-len(k)+10)+\"|\"+' '*10+str(v)\n",
    "    elif(printTable=='N' or printTable=='n'):\n",
    "        break\n",
    "    else:\n",
    "        print \"\\nInvalid Input try again\"\n",
    "        printTable=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tags are mostly unique for each article and thus plotting a bar graph wouldn't be feasible/readble.We thus only have a table for the same\n",
      "\n",
      "\n",
      "Tags                                         | Number of Article\n",
      "-------------------------------------------------------------------\n",
      "citizens commission on human rights          |          1\n",
      "powerball                                    |          1\n",
      "colorado                                     |          1\n",
      "mexico                                       |          1\n",
      "energy                                       |          1\n",
      "infinite beauty hollywood                    |          1\n",
      "san diego car accident lawyer                |          1\n",
      "gala                                         |          1\n",
      "politics                                     |          1\n",
      "ccr                                          |          1\n",
      "psychiatry: an industry of death             |          1\n",
      "boca raton                                   |          1\n",
      "lottery                                      |          1\n",
      "managed service providers                    |          1\n",
      "women's interest                             |          1\n",
      "lotto                                        |          1\n",
      "digital advertising                          |          1\n",
      "pasadena                                     |          1\n",
      "business marketing                           |          1\n",
      "marketing                                    |          1\n",
      "policy                                       |          1\n",
      "best car accident lawyer                     |          1\n",
      "lottopia                                     |          1\n",
      "app                                          |          1\n",
      "economy                                      |          1\n",
      "jackpot                                      |          1\n",
      "royal event                                  |          1\n",
      "los angeles                                  |          1\n",
      "best car accident lawyers                    |          1\n",
      "inc 5000                                     |          1\n",
      "mega millions                                |          1\n",
      "san diego accident lawyer                    |          1\n",
      "consumer goods                               |          1\n",
      "digital marketing                            |          1\n",
      "san diego car accident attorneys             |          1\n",
      "western us                                   |          1\n",
      "charity                                      |          1\n",
      "consumerism                                  |          1\n",
      "lifestyle                                    |          1\n",
      "infinite beauty florida                      |          1\n",
      "consumer general interest                    |          1\n",
      "florida                                      |          1\n",
      "ecommerce marketing                          |          1\n",
      "toluca                                       |          1\n",
      "products                                     |          1\n",
      "cchr                                         |          1\n",
      "rural                                        |          1\n",
      "infinite beauty                              |          1\n"
     ]
    }
   ],
   "source": [
    "print \"\\n\\nThe Tags are mostly unique for each article and thus plotting a bar graph wouldn't be feasible/readble. \\\n",
    "We thus only have a table for the same\\n\"\n",
    "\n",
    "printTable=\"\"\n",
    "while printTable==\"\":\n",
    "    print \"\\nThe Tags frequency table WILL BE QUITE LONG. PLEASE WAIT UNTIL IT IS COMPLETELY PRINTED, if opted to..\"\n",
    "    printTable=raw_input(\"\\nDo you want to print the Tags Analysis Table (Y/N)?: \")\n",
    "    if(printTable=='Y' or printTable=='y'):\n",
    "        maxLen=0\n",
    "        for k,v in tagsDictionary.iteritems():\n",
    "            if(maxLen<len(k)):\n",
    "                maxLen=len(k)\n",
    "\n",
    "        print \"Tags\"+' '*(maxLen+6)+\"| Number of Article\"\n",
    "        print '-'*(maxLen+32)\n",
    "        for k,v in tagsDictionary.iteritems():\n",
    "            print k+' '*(maxLen-len(k)+10)+\"|\"+' '*10+str(v)\n",
    "    elif(printTable=='N' or printTable=='n'):\n",
    "        break\n",
    "    else:\n",
    "        print \"\\nInvalid Input try again\"\n",
    "        printTable=\"\"\n",
    "\n",
    "print \"\\n\\nPlease DONT FORGET to take a look at the LocationAnalysis and CategoryAnalysis plots saved locally in your CWD: \"+os.getcwd()+\"\\n\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
